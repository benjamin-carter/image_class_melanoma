{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass8-image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMybiTUqGSgt6mmk5vg9w97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjamin-carter/image_class_melanoma/blob/master/ass8_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmveegzjfleB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from pathlib import *\n",
        "\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9GzytI-wq0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')\n",
        "\n",
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds\n",
        "\n",
        "def confusion(y, y_hat):\n",
        "  confuse = np.zeros((2,2))\n",
        "  confuse[0,0] = np.sum(y_hat[y == 1])\n",
        "  confuse[0,1] = np.sum(y_hat[y == 0])\n",
        "  confuse[1,0] = np.count_nonzero(y_hat[y == 1] == 0)\n",
        "  confuse[1,1] = np.count_nonzero(y_hat[y == 0] == 0)\n",
        "  return confuse\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8WJw_LRGPof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRp3ezAUJSJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6-d5wkj2K4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir  = Path(r\"/content/gdrive/My Drive/Current/SC_images/datadir/data_dir2_os/\")\n",
        "\n",
        "train_dir = data_dir / 'train'\n",
        "test_dir = data_dir / 'test'\n",
        "\n",
        "# data_dir  = Path(r\"/content/gdrive/My Drive/Current/images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G9OaBgTjRvI",
        "colab_type": "code",
        "outputId": "e6aaddf8-7b39-4318-92a9-4d8eea0a8ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "CLASS_NAMES = np.array([item.name for item in train_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "image_count = len(list(train_dir.glob('*/*.jpg')))\n",
        "print(CLASS_NAMES, image_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['benign' 'cancer'] 9424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbtbwXilwe6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator1 = ImageDataGenerator(rescale=1/255, rotation_range = 45)\n",
        "train_image_generator2 = ImageDataGenerator(rescale=1/255, rotation_range = 90)\n",
        "train_image_generator3 = ImageDataGenerator(rescale=1/255, vertical_flip=True)\n",
        "train_image_generator4 = ImageDataGenerator(rescale=1/255, horizontal_flip=True)\n",
        "# train_image_generator5 = ImageDataGenerator(rescale=1/255, width_shift_range = .5, height_shift_range = .5)\n",
        "train_image_generator6 = ImageDataGenerator(rescale=1/255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
        "epochs = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6snL0E-EmfO",
        "colab_type": "code",
        "outputId": "94b7cf20-6972-4a2c-d6dd-f41cad5a3ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "train_data_gen1 = train_image_generator1.flow_from_directory(directory=str(train_dir), batch_size=BATCH_SIZE, shuffle=True, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES), class_mode = 'categorical')\n",
        "train_data_gen2 = train_image_generator2.flow_from_directory(directory=str(train_dir), batch_size=BATCH_SIZE, shuffle=True, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES), class_mode = 'categorical')\n",
        "train_data_gen3 = train_image_generator3.flow_from_directory(directory=str(train_dir), batch_size=BATCH_SIZE, shuffle=True, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES), class_mode = 'categorical')\n",
        "train_data_gen4 = train_image_generator4.flow_from_directory(directory=str(train_dir), batch_size=BATCH_SIZE, shuffle=True, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES), class_mode = 'categorical')\n",
        "# train_data_gen5 = train_image_generator5.flow_from_directory(directory=str(train_dir),batch_size=BATCH_SIZE, shuffle=True,  target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "#                                                      classes = list(CLASS_NAMES), class_mode = 'categorical')\n",
        "train_data_gen6 = train_image_generator6.flow_from_directory(directory=str(train_dir),batch_size=BATCH_SIZE, shuffle=True,  target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES), class_mode = 'categorical')\n",
        "\n",
        "test_data_gen = test_image_generator.flow_from_directory(directory=str(test_dir), batch_size=BATCH_SIZE, shuffle=False, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES), class_mode = 'categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9424 images belonging to 2 classes.\n",
            "Found 9424 images belonging to 2 classes.\n",
            "Found 9424 images belonging to 2 classes.\n",
            "Found 9424 images belonging to 2 classes.\n",
            "Found 9424 images belonging to 2 classes.\n",
            "Found 1490 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBNAq2C24wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(train_data_gen6)\n",
        "# show_batch(image_batch, label_batch)\n",
        "image_batch_test, label_batch_test = next(test_data_gen)\n",
        "# show_batch(image_batch, label_batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lVaFTGE4jgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "\n",
        "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "\n",
        "# base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tlxokQ45CUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = True\n",
        "base_model.summary()\n",
        "\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)\n",
        "\n",
        "prediction_layer1 = tf.keras.layers.Dense(1024)\n",
        "pred_layer_batch1 = prediction_layer1(feature_batch_average)\n",
        "print(pred_layer_batch1.shape)\n",
        "\n",
        "drop = tf.keras.layers.Dropout(.5)\n",
        "\n",
        "prediction_layer2 = tf.keras.layers.Dense(2)\n",
        "pred_layer_batch2 = prediction_layer2(pred_layer_batch1)\n",
        "print(pred_layer_batch2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1df7E0oy6HKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#   base_model,\n",
        "#   global_average_layer,\n",
        "#   prediction_layer2\n",
        "# ])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer1,\n",
        "  drop,\n",
        "  prediction_layer2\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P_Ke0JR6Jyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwYvT6MN-nCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 10\n",
        "validation_steps = 12\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(test_data_gen, steps = validation_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-L8o2fP-fsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ds = train_data_gen.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "# test_ds = test_data_gen.batch(BATCH_SIZE)\n",
        "initial_epochs = 1\n",
        "validation_steps=12\n",
        "history = model.fit(train_data_gen1,\n",
        "                    epochs=initial_epochs,\n",
        "                    steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                    validation_data=test_data_gen,\n",
        "                    validation_steps=20 ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdj9MeEwMYaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 1\n",
        "validation_steps=12\n",
        "file_path = '/content/gdrive/My Drive/Current/SC_images/datadir/weights/'\n",
        "model.load_weights(file_path)\n",
        "history = model.fit_generator(train_data_gen1, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=validation_steps ) \n",
        "model.save_weights(file_path)\n",
        "model.load_weights(file_path)\n",
        "history = model.fit_generator(train_data_gen2, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=validation_steps ) \n",
        "model.save_weights(file_path)\n",
        "model.load_weights(file_path)\n",
        "history = model.fit_generator(train_data_gen3, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=validation_steps ) \n",
        "model.save_weights(file_path)\n",
        "model.load_weights(file_path)\n",
        "history = model.fit_generator(train_data_gen4, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=validation_steps ) \n",
        "model.save_weights(file_path)\n",
        "model.load_weights(file_path)\n",
        "# history = model.fit_generator(train_data_gen5, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=validation_steps ) \n",
        "# model.save_weights(file_path)\n",
        "# model.load_weights(file_path)\n",
        "history = model.fit_generator(train_data_gen6, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=validation_steps ) \n",
        "model.save_weights(file_path)\n",
        "model.load_weights(file_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jrNAMuhdKIY",
        "colab_type": "code",
        "outputId": "afa070fd-9c55-4a66-b923-dc9e7a2dc05b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "results = model.evaluate(test_data_gen, batch_size=BATCH_SIZE, steps = 20)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name,value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 1215s 61s/step - loss: 0.9648 - accuracy: 0.7255\n",
            "loss: 0.965\n",
            "accuracy: 0.726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0i2WdoiVv0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict_generator(test_data_gen,steps = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrvqu4wFIOVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat = np.argmax(prediction,axis=1)\n",
        "yhat[-122:]\n",
        "y_orig = np.zeros((1490,2))\n",
        "y_orig[:1368,0] = np.ones(1368)\n",
        "y_orig[1368:,1] = np.ones(122)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPB1T7d_Ivjw",
        "colab_type": "code",
        "outputId": "11f06069-0567-47b8-af78-3f54d72ffb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "confusion(y_orig[:,1],yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 24., 395.],\n",
              "       [ 98., 973.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzbb5s-RqGF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LneKnI4-uKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whj-HW8E-uYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(150,150,3)))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "base_learning_rate = 0.0001\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN5TZNLg-uVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(150,150,3)))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Dropout(0.25))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(2, activation='softmax'))\n",
        "\n",
        "base_learning_rate = 0.0001\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1FJHD7T-uQN",
        "colab_type": "code",
        "outputId": "9dd59f3b-fbe9-41d8-d40b-a0e0a61c6c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "initial_epochs = 2\n",
        "file_path = '/content/gdrive/My Drive/Current/SC_images/datadir/weights2/'\n",
        "history = model2.fit(train_data_gen1, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=12 ) \n",
        "model2.save_weights(file_path)\n",
        "model2.load_weights(file_path)\n",
        "history = model2.fit(train_data_gen2, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=12 ) \n",
        "model2.save_weights(file_path)\n",
        "model2.load_weights(file_path)\n",
        "history = model2.fit(train_data_gen3, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=12 ) \n",
        "model2.save_weights(file_path)\n",
        "model2.load_weights(file_path)\n",
        "history = model2.fit(train_data_gen4, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=1 ) \n",
        "model2.save_weights(file_path)\n",
        "model2.load_weights(file_path)\n",
        "# history = model2.fit(train_data_gen5, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=12 ) \n",
        "# model2.save_weights(file_path)\n",
        "# model2.load_weights(file_path)\n",
        "history = model2.fit(train_data_gen6, epochs=initial_epochs, steps_per_epoch = STEPS_PER_EPOCH, validation_data=test_data_gen, validation_steps=12 ) \n",
        "model2.save_weights(file_path)\n",
        "model2.load_weights(file_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "74/74 [==============================] - 939s 13s/step - loss: 0.7304 - accuracy: 0.5810 - val_loss: 0.4226 - val_accuracy: 0.9181\n",
            "Epoch 2/2\n",
            "74/74 [==============================] - 946s 13s/step - loss: 0.7310 - accuracy: 0.5823 - val_loss: 0.4226 - val_accuracy: 0.9181\n",
            "Epoch 1/2\n",
            "74/74 [==============================] - 957s 13s/step - loss: 0.7306 - accuracy: 0.5823 - val_loss: 0.4226 - val_accuracy: 0.9181\n",
            "Epoch 2/2\n",
            "43/74 [================>.............] - ETA: 6:19 - loss: 0.7348 - accuracy: 0.5785"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8FNjxrkFPQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/gdrive/My Drive/Current/SC_images/datadir/weights2/'\n",
        "model2.load_weights(file_path)\n",
        "prediction2 = model2.predict_generator(test_data_gen,steps = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKWn94zgXv5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat = np.argmax(prediction2,axis=1)\n",
        "yhat[-122:]\n",
        "y_orig = np.zeros((1490,2))\n",
        "y_orig[:1368,0] = np.ones(1368)\n",
        "y_orig[1368:,1] = np.ones(122)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O92vx61gUcMy",
        "colab_type": "code",
        "outputId": "00c1326c-82f0-4097-8795-5000a2f1884f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "confusion(y_orig[:,1], yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 71., 643.],\n",
              "       [ 51., 725.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raqezltx0jT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mel_dir = train_dir / 'mel'\n",
        "train_df_dir = train_dir / 'df'\n",
        "train_bkl_dir = train_dir / 'bkl'\n",
        "train_bcc_dir = train_dir / 'bcc'\n",
        "train_akiec_dir = train_dir / 'akiec'\n",
        "train_vasc_dir = train_dir / 'vasc'\n",
        "train_nv_dir = train_dir / 'nv'\n",
        "\n",
        "test_mel_dir = test_dir / 'mel' \n",
        "test_df_dir = test_dir / 'df' \n",
        "test_bkl_dir = test_dir / 'bkl' \n",
        "test_bcc_dir = test_dir / 'bcc'\n",
        "test_akiec_dir = test_dir /  'akiec'\n",
        "test_vasc_dir = test_dir / 'vasc'\n",
        "test_nv_dir = test_dir /  'nv'\n",
        "\n",
        "num_mel_train = len(os.listdir(train_mel_dir))\n",
        "num_df_train = len(os.listdir(train_df_dir))\n",
        "num_bkl_train = len(os.listdir(train_bkl_dir))\n",
        "num_bcc_train = len(os.listdir(train_bcc_dir))\n",
        "num_akiec_train = len(os.listdir(train_akiec_dir))\n",
        "num_vasc_train = len(os.listdir(train_vasc_dir))\n",
        "num_nv_train = len(os.listdir(train_nv_dir))\n",
        "\n",
        "num_mel_test = len(os.listdir(test_mel_dir))\n",
        "num_df_test = len(os.listdir(test_df_dir))\n",
        "num_bkl_test = len(os.listdir(test_bkl_dir))\n",
        "num_bcc_test = len(os.listdir(test_bcc_dir))\n",
        "num_akiec_test = len(os.listdir(test_akiec_dir))\n",
        "num_vasc_test = len(os.listdir(test_vasc_dir))\n",
        "num_nv_test = len(os.listdir(test_nv_dir))\n",
        "\n",
        "total_train = num_mel_train + num_df_train + num_bkl_train + num_bcc_train + num_akiec_train + num_vasc_train + num_nv_train\n",
        "total_test = num_mel_test + num_df_test + num_bkl_test + num_bcc_test + num_akiec_test + num_vasc_test + num_nv_test\n",
        "\n",
        "print('total training mel images:', num_mel_train)\n",
        "print('total training df images:', num_df_train)\n",
        "print('total training bkl images:', num_bkl_train)\n",
        "print('total training bcc images:', num_bcc_train)\n",
        "print('total training akiec images:', num_akiec_train)\n",
        "print('total training vasc images:', num_vasc_train)\n",
        "print('total training nv images:', num_nv_train)\n",
        "\n",
        "print('total testing mel images:', num_mel_test)\n",
        "print('total testing df images:', num_df_test)\n",
        "print('total testing bkl images:', num_bkl_test)\n",
        "print('total testing bcc images:', num_bcc_test)\n",
        "print('total testing akiec images:', num_akiec_test)\n",
        "print('total testing vasc images:', num_vasc_test)\n",
        "print('total testing nv images:', num_nv_test)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total testing images:\", total_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqu-VvnxxgNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(train_dir/'*/*'))\n",
        "list_ds_test = tf.data.Dataset.list_files(str(test_dir/'*/*'))  \n",
        "\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "labeled_ds\n",
        "labeled_test_ds = list_ds_test.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "labeled_test_ds\n",
        "\n",
        "for image, label in labeled_ds.take(2):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoMOH5Kgx0Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = prepare_for_training(labeled_ds)\n",
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "test_ds = prepare_for_training(labeled_test_ds)\n",
        "image_batch_test, label_batch_test = next(iter(test_ds))\n",
        "\n",
        "# train_ds = labeled_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "# test_ds = labeled_test_ds.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbP2peDj3gh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYHEXmvIgNXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_label_name = metadata.features['label'].int2str\n",
        "\n",
        "for image, label in raw_train.take(2):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))\n",
        "  print(image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTY7E-zDgv_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 160 # All images will be resized to 160x160\n",
        "\n",
        "def format_example(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ssQG95gypp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = raw_train.map(format_example)\n",
        "validation = raw_validation.map(format_example)\n",
        "test = raw_test.map(format_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnh5sjHyg2gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3uRjHJCg-LC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "test_batches = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MksZyhXZimXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_epochs = 10\n",
        "validation_steps=20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lvliTosip5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfRPO1zKi0G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}